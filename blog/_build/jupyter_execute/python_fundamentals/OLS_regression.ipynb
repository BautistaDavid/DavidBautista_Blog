{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href='https://colab.research.google.com/github/BautistaDavid/DavidBautista_Blog/blob/main/blog/python_fundamentals/OLS_regression.ipynb' target='_parent'><img src='https://colab.research.google.com/assets/colab-badge.svg' alt='Open In Colab'/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-waPX0rxGNM"
   },
   "source": [
    "## Stata? I Only Know Python\n",
    "\n",
    "The idea of this class is to mimic the typical output of a Stata least squares regression.Below you can see an example of the output of a regression of this type in Stata using the 'crime1' database from the Wooldrige Econometrics book.\n",
    "\n",
    "Excuting the comand ```reg inc86 pcnv avgsen tottime``` the output is: \n",
    "\n",
    "\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/BautistaDavid/DavidBautista_Blog/main/blog/media/stata_caprute.JPG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byO4XY3Y10Wi"
   },
   "source": [
    "### ¡Time To Create! \n",
    "\n",
    "As I mentioned before, the idea is to create a class that allows us to replicate Stata output in python. So let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AFqX1X6pHWTl"
   },
   "outputs": [],
   "source": [
    "# We have to import some modules to use matrix and calculate statistics\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy.stats as sst\n",
    "from scipy import stats\n",
    "\n",
    "class Lineal_Reg(object):\n",
    "  def __init__(self,Y,X,alpha=0.05,intercept = True):\n",
    "    self.intercept = intercept\n",
    "    self.Y = Y.to_numpy().reshape(len(Y),1)\n",
    "    if self.intercept == True: \n",
    "      self.X = np.c_[np.ones(self.Y.shape[0]),X.to_numpy()] if len(X.shape) !=1 else np.c_[np.ones(len(X)),X.to_numpy().reshape([len(X),1])]     \n",
    "    elif self.intercept == False: \n",
    "      self.X = X.to_numpy() if len(X.shape) !=1 else X.to_numpy().reshape([len(X),1])\n",
    "\n",
    "    self.alpha = alpha\n",
    "    self.names = X.columns if len(X.shape)!=1 else [X.name]\n",
    "    self.n = self.X.shape[0]\n",
    "    self.k = self.X.shape[1] -1 if len(X.shape) !=1 else 1\n",
    "    self.gl = self.n - self.k -1\n",
    "  \n",
    "  class fit():\n",
    "    def __init__(self):\n",
    "      Lineal_Reg.__init__(self,Y,X,alpha=0.05,intercept = True)\n",
    "      self.betas = (np.linalg.inv(self.X.T@self.X)@self.X.T@self.Y)\n",
    "  \n",
    "    def __anova(self):\n",
    "      self.residuals = self.Y - (self.X @ self.betas)\n",
    "      self.SEC = np.sum(np.square(self.X @ self.betas -np.mean(self.Y)))\n",
    "      self.SRC = np.sum(np.square(self.residuals))\n",
    "      self.STC = np.sum(np.square(self.Y-np.mean(self.Y)))\n",
    "      self.R_2 = 1-self.SRC/self.STC\n",
    "      self.statistic_F = (self.R_2 / self.k) / ((1-self.R_2)/(self.n - self.k -1))\n",
    "      self.MS_model = self.SEC / self.k  \n",
    "      self.MS_residual = self.SRC / self.gl \n",
    "      self.MS_total = self.STC / (self.n - 1)\n",
    "\n",
    "    def __table_results(self):\n",
    "      self.m_covariances = (self.SRC/self.gl) * (np.linalg.inv(self.X.T @ self.X))\n",
    "      self.variances = np.diag(self.m_covariances)\n",
    "      self.standard_error = np.sqrt(self.variances).ravel().tolist() # ya quedo en lista\n",
    "      self.t_values = [betas/errors for (betas,errors) in zip(self.betas.ravel().tolist(),self.standard_error)]\n",
    "      self.p_values = [stats.t.sf(np.abs(t_val), self.n-1)*2 for t_val in self.t_values]  #t,Gl\n",
    "    #intervals \n",
    "      self.t_level = sst.t.ppf(1 - self.alpha/2, df=self.n - self.k - 1 )  # df = n-k-1\n",
    "      self.intervals = [sorted([beta - (errcoef * self.t_level),beta + (errcoef * self.t_level)]) for (beta,errcoef) in zip(self.betas.ravel().tolist(),self.standard_error)]\n",
    "  \n",
    "    @property # decorator to turn a method in an attribute \n",
    "    def summary(self):\n",
    "      self.__anova()\n",
    "      self.__table_results()\n",
    "      panel = pd.DataFrame(index=['Model','Residuals','Total'])\n",
    "      panel['SS'] = [round(i,2) for i in [self.SEC,self.SRC,self.STC]]\n",
    "      panel['df'] = [self.k,self.gl,self.n-1]\n",
    "      panel['MS'] = [round(i,2) for i in [self.MS_model,self.MS_residual,self.MS_total]]\n",
    "      panel['  '] = ['   ','   ','   ']\n",
    "      panel['    '] = [f'No. Observations = {self.n}',f'F{self.k,self.gl} = {round(self.statistic_F,2)}',f'R-squared = {round(self.R_2,4)}']   # Esto toca organizarlo mejor  \n",
    "   \n",
    "      results=pd.DataFrame(index= ['_Cons']+ [i for i in self.names]) if self.intercept == True else pd.DataFrame(index= [i for i in self.__names])\n",
    "      results['Coefficients'] = [round(i,3) for i in self.betas.ravel().tolist()]\n",
    "      results['S. Error'] = self.standard_error\n",
    "      results['t'] = [round(i,2) for i in self.t_values]\n",
    "      results['P'] = [round(i,4) for i in self.p_values] \n",
    "      results['Confidence Intervals'] = [(round(i[0],6),round(i[1],6)) for i in self.intervals]\n",
    "      print(panel)\n",
    "      print()\n",
    "      print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¡Time To Test!\n",
    "\n",
    "Now using the wooldridge python package we can try to execute the same regression model with our class and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2GAv1qhv53W",
    "outputId": "e0382b8d-fb75-4870-9a6d-5e3641a69ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    SS    df        MS                              \n",
      "Model        121506.84     3  40502.28       No. Observations = 2725\n",
      "Residuals  11970834.58  2721   4399.42             F(3, 2721) = 9.21\n",
      "Total      12092341.43  2724   4439.19              R-squared = 0.01\n",
      "\n",
      "         Coefficients  S. Error      t       P    Confidence Intervals\n",
      "_Cons          56.551  1.725994  32.76  0.0000  (53.166824, 59.935609)\n",
      "pcnv           -1.005  3.217262  -0.31  0.7548   (-7.313471, 5.303577)\n",
      "avgsen         -0.449  0.975871  -0.46  0.6452   (-2.362842, 1.464203)\n",
      "tottime        -1.121  0.743165  -1.51  0.1315   (-2.578547, 0.335901)\n"
     ]
    }
   ],
   "source": [
    "import wooldridge as wd # Dont Forget to install wooldridge package\n",
    "df = wd.data('crime1')\n",
    "\n",
    "Y = df['inc86']\n",
    "X = df[['pcnv','avgsen','tottime']]\n",
    "\n",
    "model = Lineal_Reg(Y,X,alpha=0.05) # Creating the object\n",
    "reg = model.fit() # using fit method \n",
    "reg.summary # Using summary attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Talk A Little About What We created ...\n",
    "\n",
    "The class is mainly composed of two parts, the first is an initiator function ```__init__()``` where the first attributes of the object are created and manipulated, which in this case will be the arrays of dependent and independent variables according to the regression. Apart from this initiator function, a class called ```fit()``` is created within our first class, the idea is that this is started and the calculation of the betas will be executed, however it is saved and can be accessed using the method converted to summary attribute, which generates all the output with the help of other methods generated within the same subclass. Methods such ```__anova()``` and ```__table_results``` are hidden to the users, they only work inside the class, we can do thath usgin Methods such ```__anova()``` and ```__table_results``` are hidden to the users, they only work inside the class, we can do that using ```__``` before the name of a method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Conclusions ...\n",
    "\n",
    "The main conclusion that stands out from this project is that the open source philosophy and technologies allow us to develop thousands of ideas, codes and applications that some companies would sell. In my case I have the Stata17 license because my university pays for it, however using python I was able to replicate one of the most popular outputs for students of basic econometrics courses."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMKLEK6hb5XMbQL0spDlOd6",
   "include_colab_link": true,
   "name": "OLS_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0da415c9e4168631dca5b2115af7ca136eaae3b6c6732b5609a1f249258bc9bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}